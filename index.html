<!DOCTYPE html>
<html lang="en">

  <head>
    <title>
      UnImplicit: Understanding Implicit and Underspecified Language
    </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Prevent caching -->
    <META HTTP-EQUIV="Pragma" CONTENT="no-cache">
    <META HTTP-EQUIV="Expires" CONTENT="-1">
    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet" media="screen">
    
    <style>
      /* Customize container */
      @media (min-width: 968px) {
	  .container {
	      max-width: 968px;
	  }
      }
      .container-narrow > hr {
	  margin: 30px 0;
      }
      
      /* Customize dropdown menu */
      .dropdown {
	  cursor: pointer;
      }
      .dropdown sup {
	  color: rgb(66, 139, 202);
      }
      .dropdown sup:hover, .dropdown sup:focus {
	  color: rgb(42, 100, 150);
	  text-decoration: underline;
      }
      .dropdown-menu {
	  min-width: 500px;
	  left: -200px;
      }
      .dropdown-menu li {
	  margin-bottom: .5em;
	  /*border-top-style:solid; padding-left:10px;*/
      }
    </style>
  </head>
  
  <body data-spy="scroll" data-target="#navbar" data-offset="70" onload="load()">
    
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">UnImplicit</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="#organizers">Organizers &amp; Committee</a></li>
		  <li><a href="#dates">Important Dates</a></li>
		  <li><a href="#speakers">Speakers</a></li>
		  <li><a href="#program">Program</a></li>
		  <li><a href="#submission">Submission Information</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <!--li><a href="https://www.emnlp-ijcnlp2019.org/">EMNLP-IJCNLP 2019</a></li-->
          </ul>
        </div>
      </div>
    </nav>
    
    <div class="container">
      
      <br/>
      <br/>      
      <br/>
      <center><h2 id="top"><b>UnImplicit: The Third Workshop on<br/>
	    Understanding Implicit and Underspecified Language</b></h2></center>
      <center><h4>at EACL 2024, Malta</h4></center>
      <br/>
      	        <img src="logo.png" alt="logo" style="float:left;width:300px;height:300px;">

      <p>Real language is underspecified, vague, and ambiguous. 
Indeed, past work (Zipf, 1949; Piantadosi, 2012) has suggested that ambiguity may be an inextricable feature of natural language, resulting from competing communicative pressures. 
Resolving the meaning of language is a never-ending process of making inferences based on implicit knowledge. 
For example, we know that ``the girl saw the man with the telescope'' is ambiguous and could refer to two situations, while ``the girl saw the man with the hamburger'' is not, or that ``near'' in ``the house near the airport'' and ``the ant near the crumb'' does not refer to the same distance.
Being able to capture this kind of knowledge is central to building systems with a human-like understanding of language, as well as to providing a full account of natural language itself. </p>
        <p>While underspecified, ambiguous, and implicit language rarely poses a problem for language speakers, it can challenge even the best models. 
For example, despite recent major successes in NLP coming from large language models (LLMs), it is not clear that models capture ambiguous language in a human-like fashion (Liu, 2023; Stengel-Eskin, 2023).
The same has been argued for multimodal NLP. (Pezzelle, 2023), for example, showed that CLIPScore is sensitive to underspecified captions.
Tackling these kinds of linguistic phenomena represents a new frontier in NLP research, enabled by major progress on more clear-cut tasks. 
      <p>Past work in underspecified language has tackled several directions.
Some semantic representations have sought to explicitly represent underspecification (Copestake, 2005; Bos, 2004). </p>
Other work has begun to recognize that perfect annotator agreement is often unrealistic, especially when using categorical labels for tasks like natural language inference (Chen, 2020; Nie, 2020; Pavlick, 2019). 
This workshop hopes to attract work embracing disagreement between annotators as a source of signal about underspecification and ambiguity.</p>
	    
      <p>In order to resolve the meaning of underspecified and ambiguous language, we often employ additional modalities and information acquired through embodied experience (Bisk, 2020). 
For example ``the girl saw the man with the telescope'' becomes unambiguous if paired with an image of a man holding a telescope. 
In contrast, NLP typically considers language in isolation, removed from the context in which it is typically found. 
This workshop will highlight multimodal inputs, especially visual ones, as sources of information for resolving underspecification. 
These inputs can themselves pose additional challenges, e.g. through ambiguous images or videos (Bhattacharya, 2019; Sanders, 2022). </p>

      <p>The goal of the third edition of the workshop is to continue eliciting future progress on processing implicit, underspecified and ambiguous language with a strong focus on annotation ambiguity, multimodality and pragmatics. Similar to the first two editions, we would accept theoretical and practical contributions (long, short and non-archival) on all aspects related to the workshop topic.</p>

	    
      <a name="speakers"></a>
      <div class="page-header">
	<h1>Invited Speakers</h1>
      </div>
      <div class="row">
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://www.malihealikhani.com">Malihe Alikhani</a></h2>Northeastern University
	    </div>
	    <div class="panel-body">
	      <b>TBD</b><br/>
		    		<img src="malihe-alikhani.jpg" alt="logo" style="float:left;width:100px;height:100px;" hspace="10" vspace="10">
	    </div>
	  </div>
	</div>
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://pages.ucsd.edu/~bkbergen/">Benjamin Bergen</a></h2>UCSD
		  </div>
	    <div class="panel-body">
	      <b>TBD</b><br/>
       <img src="benjamin-bergen.jpg" alt="logo" style="float:left;width:100px;height:100px;" hspace="10" vspace="10">
		  </div>
	  </div>
	</div>
      </div>
	 
	


	    	    
	    <div class="page-header">
      <a name="dates"></a>
      <div class="page-header">
	<h1>Important Dates</h1>
      </div>
      <ul>
	<li>October 20, 2023: First Call for Workshop Papers</li>
	<li>November 15, 2023: Second Call for Workshop Papers</li>
	<li>December 11, 2023: Third Call for Workshop Papers</li>
	<li>December 18, 2023: Workshop paper due</li>
	<li>January 17, 2024: Direct Submission deadline (pre-reviewed ARR & main conference)</li>
	<li>January 20, 2024: Notification of Acceptance</li>
	<li>January 30, 2024: Camera-ready papers due</li>
	<li>February 7, 2024: Proceedings due</li>
	<li>March 21-22, 2024: Workshop Dates</li>
      </ul>

	    
	    <div class="page-header">
      <a name="submission"></a>
      <div class="page-header">
	<h1>Submission</h1>
      </div>
We invite two types of submissions:
<ul>
	<li>Archival: long (up to 8 pages) or short (up to 4 pages) papers, with unlimited additional pages for references. These papers should report on complete, original and unpublished research and cannot be under submission elsewhere. If accepted, archival papers will appear in the workshop proceedings.
<li>Non-archival: Extended abstracts (up to 2 pages) or copy of submission/publication, which can take two forms: 
<ul>
	<li>Works in progress, that are not yet mature enough for a full submission. Up to 2 pages, with unlimited pages for references.
<li>Already published work, or work currently under submission elsewhere, which can be submitted as a copy of the submission/publication (please indicate the venue where it has been submitted to).
	    </ul>
	</ul>
There are two possible deadlines for the submissions!:
<ul>
	<li>Standard Submission: This deadline, on the 18th of December 2023, is for papers which do not have any reviews through ARR yet. Papers submitted on this deadline will be reviewed by the workshop PCs.
		<ul>li>All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").
		li><p>Please submit your papers at <a href="https://openreview.net/group?id=eacl.org/EACL/2024/Workshop/UnImplicit">https://openreview.net/group?id=eacl.org/EACL/2024/Workshop/UnImplicit</a></p>
		li><p>Please use the EACL style templates.</p></ul>
<li>Direct Submission (with reviews): This submission deadline, on January 17th 2024, is for papers that are either pre-reviewed by ARR, rejected from EACL (with reviews) and for Findings papers looking for a presentation slot.
	<ul>
	<li>All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").
<li>Please submit using the form (not the openreview link!), which we will post here closer to the deadline!
	<li>Please use the EACL style templates.
	    </ul>
	</ul>

	    <p>If you have any questions please email us at unimplicitworkshop -AT- gmail.com</p>

		   <ul> We welcome submissions related to, but not limited to, the following topics:
<li>Creating corpora or new annotations for underspecified, vague, or ambiguous language
<li>Studies of annotator disagreement
<li>Methods of resolving underspecification, vagueness, or ambiguity
<li>Studies of how multimodal settings interact with underspecification in language
<li>Ambiguities in non-linguistic domains, like images or videos
<li>Perspectives on the role of vagueness and ambiguity in NLP</ul>


	    <div class="page-header">
      <a name="organizers"></a>
      <div class="page-header">
	<h1>Organizers</h1>
      </div>
        	<h2>Organizers</h2>
      <ul class="list-unstyled">
	<li><a target="_blank" href="https://sandropezzelle.github.io">Sandro Pezzelle</a>, University of Amsterdam</li>
	<li><a target="_blank" href="https://valentinapy.github.io">Valentina Pyatkin</a>, AI2 and University of Washington</li>
	<li><a target="_blank" href="https://esteng.github.io">Elias Stengel-Eskin</a>, UNC Chapel Hil</li>
	<li><a target="_blank" href="https://alisawuffles.github.io">Alisa Liu</a>, University of Washington</li>
	<li><a target="_blank" href="https://dpfried.github.io">Daniel Fried</a>, CMU</li>
      </ul>
        <h2>Advisory Committee</h2>
      <ul class="list-unstyled">
	<li><a target="_blank" href="https://www.ims.uni-stuttgart.de/en/institute/team/Roth-00006/">Michael Roth</a>, Stuttgart University</li>
	<li><a target="_blank" href="https://research.biu.ac.il/researcher/prof-reut-tsarfaty/">Reut Tsarfaty</a>, Bar-Ilan University</li>
	<li><a target="_blank" href="https://www.cs.bgu.ac.il/~yoavg/uni/">Yoav Goldberg</a>, Bar-Ilan University and AI2</li>
      </ul>

      <h3>Program Committee<a name="committee" ></a></h3>

      <ul class="list-unstyled">
<li>Sebastian Pado</li>
<li>Vera Demberg</li>
<li>Elior Sulem</li>
<li>Daniel Hershcovich</li>
<li>Sara Tonelli</li>
<li>Nathan Schneider</li>
<li>Yanai Elazar</li>
<li>Chris Potts</li>
<li>Jennifer Hu</li>
<li>Tiago Timponi Torrent</li>
<li>Michael Elhadad</li>
<li>Zhaofeng Wu</li>
<li>Lucy Li</li>
<li>Sofia Serrano</li>
<li>Dmitry Nikolaev</li>
<li>Nan-Jiang Jiang</li>
<li>Julian Michael</li>
<li>Roma Patel</li>
<li>Ece Takmaz</li>
<li>Aida Nematzadeh</li>
      </ul>

      <br/>
      <br/>
      <br/>
      
    </div>    
  </body>
</html>
