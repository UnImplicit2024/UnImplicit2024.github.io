<!DOCTYPE html>
<html lang="en">

  <head>
    <title>
      UnImplicit: Understanding Implicit and Underspecified Language
    </title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Prevent caching -->
    <META HTTP-EQUIV="Pragma" CONTENT="no-cache">
    <META HTTP-EQUIV="Expires" CONTENT="-1">
    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet" media="screen">
    
    <style>
      /* Customize container */
      @media (min-width: 968px) {
	  .container {
	      max-width: 968px;
	  }
      }
      .container-narrow > hr {
	  margin: 30px 0;
      }
      
      /* Customize dropdown menu */
      .dropdown {
	  cursor: pointer;
      }
      .dropdown sup {
	  color: rgb(66, 139, 202);
      }
      .dropdown sup:hover, .dropdown sup:focus {
	  color: rgb(42, 100, 150);
	  text-decoration: underline;
      }
      .dropdown-menu {
	  min-width: 500px;
	  left: -200px;
      }
      .dropdown-menu li {
	  margin-bottom: .5em;
	  /*border-top-style:solid; padding-left:10px;*/
      }
    </style>
  </head>
  
  <body data-spy="scroll" data-target="#navbar" data-offset="70" onload="load()">
    
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">UnImplicit</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="#organizers">Organizers &amp; Committee</a></li>
		  <li><a href="#dates">Important Dates</a></li>
		  <li><a href="#speakers">Speakers</a></li>
		  <li><a href="#program">Program</a></li>
		  <li><a href="#submission">Submission Information</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <!--li><a href="https://www.emnlp-ijcnlp2019.org/">EMNLP-IJCNLP 2019</a></li-->
          </ul>
        </div>
      </div>
    </nav>
    
    <div class="container">
      
      <br/>
      <br/>      
      <br/>
      <center><h2 id="top"><b>UnImplicit: The Third Workshop on<br/>
	    Understanding Implicit and Underspecified Language</b></h2></center>
      <center><h4>at EACL 2024, Malta, March 21</h4></center>
	    <center><h5>If you have any questions please email us at unimplicitworkshop -AT- gmail.com</h5></center>

      <br/>
      	        <img src="logo.png" alt="logo" style="float:left;width:300px;height:300px;">

      <p>Real language is underspecified, vague, and ambiguous. 
Indeed, past work (Zipf, 1949; Piantadosi, 2012) has suggested that ambiguity may be an inextricable feature of natural language, resulting from competing communicative pressures. 
Resolving the meaning of language is a never-ending process of making inferences based on implicit knowledge. 
For example, we know that ``the girl saw the man with the telescope'' is ambiguous and could refer to two situations, while ``the girl saw the man with the hamburger'' is not, or that ``near'' in ``the house near the airport'' and ``the ant near the crumb'' does not refer to the same distance.
Being able to capture this kind of knowledge is central to building systems with a human-like understanding of language, as well as to providing a full account of natural language itself. </p>
        <p>While underspecified, ambiguous, and implicit language rarely poses a problem for language speakers, it can challenge even the best models. 
For example, despite recent major successes in NLP coming from large language models (LLMs), it is not clear that models capture ambiguous language in a human-like fashion (Liu, 2023; Stengel-Eskin, 2023).
The same has been argued for multimodal NLP. (Pezzelle, 2023), for example, showed that CLIPScore is sensitive to underspecified captions.
Tackling these kinds of linguistic phenomena represents a new frontier in NLP research, enabled by major progress on more clear-cut tasks. 
      <p>Past work in underspecified language has tackled several directions.
Some semantic representations have sought to explicitly represent underspecification (Copestake, 2005; Bos, 2004). </p>
Other work has begun to recognize that perfect annotator agreement is often unrealistic, especially when using categorical labels for tasks like natural language inference (Chen, 2020; Nie, 2020; Pavlick, 2019). 
This workshop hopes to attract work embracing disagreement between annotators as a source of signal about underspecification and ambiguity.</p>
	    
      <p>In order to resolve the meaning of underspecified and ambiguous language, we often employ additional modalities and information acquired through embodied experience (Bisk, 2020). 
For example ``the girl saw the man with the telescope'' becomes unambiguous if paired with an image of a man holding a telescope. 
In contrast, NLP typically considers language in isolation, removed from the context in which it is typically found. 
This workshop will highlight multimodal inputs, especially visual ones, as sources of information for resolving underspecification. 
These inputs can themselves pose additional challenges, e.g. through ambiguous images or videos (Bhattacharya, 2019; Sanders, 2022). </p>

      <p>The goal of the third edition of the workshop is to continue eliciting future progress on processing implicit, underspecified and ambiguous language with a strong focus on annotation ambiguity, multimodality and pragmatics. Similar to the first two editions, we would accept theoretical and practical contributions (long, short and non-archival) on all aspects related to the workshop topic.</p>

	    		  <p> We welcome submissions related to, but not limited to, the following topics:
<li>Creating corpora or new annotations for underspecified, vague, or ambiguous language
<li>Studies of annotator disagreement
<li>Methods of resolving underspecification, vagueness, or ambiguity
<li>Studies of how multimodal settings interact with underspecification in language
<li>Ambiguities in non-linguistic domains, like images or videos
<li>Perspectives on the role of vagueness and ambiguity in NLP</ul>
	    
      <a name="speakers"></a>
      <div class="page-header">
	<h1>Invited Speakers</h1>
	      </div>
      <div class="row">
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://alexwarstadt.com">Alex Warstadt</a></h2>ETH
	    </div>
	    <div class="panel-body">
	      <b> "What's the point?" How relevance shapes language learning and inference in humans and machines.</b><br/>
		    		<img src="warstadt.jpg" alt="logo" style="float:left;width:100px;height:100px;" hspace="10" vspace="10">
	    Humans always use language to achieve some purpose. This talk starts from this central tenet of pragmatics and follows several threads that emerge from it. The first half focuses on humans. I begin with experiments that test how we judge the relevance or utility of a new piece of information. Then, I show how reasoning about utility, formalized in a Rational Speech Acts model, can help us draw inferences about the presuppositions of our conversational partners. The second half focuses on language models. How do these models that see only distributional information learn semantic relations such as entailment? I present theoretical results to support the claim that the key to this feat is the assumption that the underlying distribution is generated by rational pragmatic agents. But while this argument goes through in theory, next-word prediction may not be the fastest or most human-like way to learn language. I end by discussing how ongoing and future work inspired by RLHF aims to introduce notions of communicative success as a new learning signal for training more data-efficient and pragmatic language models.

	    </div>
	  </div>
	</div>
      </div>
      <div class="row">
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://www.malihealikhani.com">Malihe Alikhani</a></h2>Northeastern University
	    </div>
	    <div class="panel-body">
	      <b>From Ambiguity to Clarity: Navigating Uncertainty in Human-Machine Conversations</b><br/>
		    		<img src="malihe-alikhani.jpg" alt="logo" style="float:left;width:100px;height:100px;" hspace="10" vspace="10">
This talk delves into the intricacies of uncertainty in human-machine dialogue, mainly focusing on the challenges and solutions related to ambiguities arising from impoverished contextual representations. We examine how linguistically informed context representations can mitigate data-related uncertainty in a deployed dialogue system similar to Alexa. We acknowledge that certain types of data-related uncertainty are unavoidable and investigate the capabilities of modern billion-scale language models in representing this form of uncertainty in conversations. Shifting our focus to epistemic uncertainty arising from misaligned background knowledge between humans and machines, we explore strategies for quantifying and reducing this form of uncertainty. Our discussion encompasses various facets of human-machine convergence, including lexical diversity, question generation, fairness, and pragmatics. By leveraging machine learning theory and cognitive science insights, we aim to quantify epistemic uncertainty and propose algorithms that improve grounding between humans and machines. This exploration sheds light on the theoretical underpinnings of uncertainty in dialogue systems and offers practical solutions for improving human-machine communication.	    
</div>
	  </div>
	</div>
	<div class="col-sm-6">
	  <div class="panel panel-default">
	    <div class="panel-heading">
	      <h2 class="panel-title"><a href="https://pages.ucsd.edu/~bkbergen/">Benjamin Bergen</a></h2>UCSD
		  </div>
	    <div class="panel-body">
	      <b>Lexical and referential ambiguity in humans and language models</b><br/>
       <img src="benjamin-bergen.jpg" alt="logo" style="float:left;width:100px;height:100px;" hspace="10" vspace="10">
		    Linguistic ambiguity poses processing challenges to both humans and machines. In this talk, I begin with recent research from my lab aiming to understand why lexical ambiguity exists in the first place. Ambiguity may seem like poor design for a communication system—for instance, it’s almost entirely absent from programming languages. We test and reject a well-known proposed explanation for lexical ambiguity—that homophones exist to increase efficiency for language production. We find that languages are in fact less ambiguous than one would expect by chance, and that if anything the amount and distribution of ambiguity in language benefits comprehenders, rather than producers. Next, I discuss our research on how humans represent ambiguous words, finding that human meaning representations have both categorical aspects as well as continuous ones. This differentiates human lexical representations from those of Large Language Models, which are continuous. And finally I discuss referential ambiguity effects—how humans resolve ambiguous pronouns in context. For instance, when presented with a sentence like “When the steel ball fell on the glass table, it broke.” English speakers tend to judge that the table is the more likely the referent of “it”, likely due to world knowledge. These judgments are not fully explained by predictions of pre-trained Large Language Models, which suggests that humans are likely relying on world knowledge mechanisms not available through learning from distributional statistics of language alone.
		  </div>
	  </div>
	</div>
      </div>

      <a name="program"></a>
      <div class="page-header">
	<h1>Workshop Program</h1><br/>
	(all times shown in GMT+1, for Thursday the 21st of March 2024)
      </div>
<p>
  <table class="table table-striped">
    <tbody>
      <tr>
	<td>09:30</td>
	<td><b>Opening (Room: Bastion 1)</b></td>
      </tr>
      <tr>
	<td class="success">9:45</td>
	<td>
	  <b>Invited talk (Room: Bastion 1)</b><br/>
	  <!-- title <br/-->
	  <i>Alex Warstadt</i></td>
     </tr>
	          <tr>
	<td class="success">10:45</td>
	<td>
	  <b>Coffee Break</b><br/>
     </tr>
      <tr>
	<td class="success">11:15</td>
	<td><b>In-person poster session (Room: Terrace Suite)</b></td>
      </tr>
      <tr>
	<td class="success"></td><td>Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests<br/>
	  <i>Brielen Madureira, David Schlangen</i></td></tr>
      <tr>
	<td class="success"></td><td>More Labels or Cases? Assessing Label Variation in Natural Language Inference<br/>
	  <i>Cornelia Gruber, Katharina Hechinger, Matthias Assenmacher, Göran Kauermann, Barbara Plank</i></td></tr>
      <tr>
	<td class="success"></td><td>Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical System for Punctuation Restoration<br/>
	  <i>Xiliang Zhu, Chia-Tien Chang, Shayna Gardiner, David Rossouw, Jonas Robertson</i></td></tr>
      <tr>
	<td class="success"></td><td>Assessing the Significance of Encoded Information in Contextualized Representations to Word Sense Disambiguation<br/>
	  <i>Deniz Ekin Yavas</i></td></tr>      
      <tr>
	<td class="success"></td><td>Below the Sea (with the Sharks): Probing Textual Features of Implicit Sentiment in a Literary Case-study<br/>
	  <i>Yuri Bizzoni, Pascale Feldkamp</i></td></tr>      
      <tr>
	<td class="success"></td><td>Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification<br/>
	  <i>Géraud Faye, Benjamin Icard, Morgane Casanova, Julien Chanson, François Maine, François Bancilhon, Guillaume Gadek, Guillaume Gravier, Paul Égré</i></td></tr>      
      <tr>
	<td class="success"></td><td>Different Tastes of Entities: Investigating Human Label Variation in Named Entity Annotations<br/>
	  <i>Siyao Peng, Zihang Sun, Sebastian Loftus, Barbara Plank</i></td></tr>      
      <tr>
	<td class="success"></td><td>Colour Me Uncertain: Representing Vagueness with Probabilistic Semantics<br/>
	  <i>Kin Chun Cheung, Guy Emerson</i></td></tr>      
      <tr>
	<td class="info"><b>Unarchival</b></td><td>Similarity-weighted Construction of Contextualized Commonsense Knowledge Graphs for Knowledge-intense Argumentation Tasks<br/>
          <i>Moritz Plenz, Juri Opitz, Philipp Heinisch, Philipp Cimiano, Anette Frank</i></td></tr>
      <tr>
	<td class="info"></td><td>Are You Serious? Handling Disagreement When Annotating Conspiracy Theory Texts<br/>
	  <i>Ashley Hemm, Sandra Kübler, Michelle Seelig, John Funchion, Manohar Narayanamurthi, Kamal Premaratne, Daniel Verdear, Stefan Wuchty</i></td></tr>
      <tr>
	<td class="info"></td><td>Exploiting Large Language Models and Prompt Engineering Techniques to detect and classify implicit content in Italian political discourse<br/>
	  <i>Walter Paci</i></td></tr>
    <tr>
	<td class="info"></td><td>A Taxonomy of Ambiguity Types for NLP<br/>
	  <i>Margaret Y. Li, Alisa Liu, Zhaofeng Wu, Noah A. Smith</i></td></tr>
      <tr>
	<td class="success">12:30</td>
	<td><b>Lunch</b></td>
      </tr>
<tr>
	<td class="success">13:45</td>
	<td><b>Oral Presentations</b>
      </td></tr>
      <tr>
      <tr>
	<td class="success">14:30</td>
	<td>
	  <b>Invited talk (Room: Bastion 1)</b> <br/>
	  <i>Malihe Alikhani</i>
	</td>
      </tr>
	          <tr>
	            <tr>
	      <td class="success">15:30</td>
	<td><b>Coffee Break</b>
      </td></tr>
      <tr>
	<td class="success">16:00</td>
	<td>
	  <b>Invited talk (Room: Bastion 1)</b> <br/>
	  <i>Benjamin Bergen</i>
	</td>
      </tr>
	<td>17:00</td>
	<td><b>(Official) closing (Room: Bastion 1)</b></td>
      </tr>
    </tbody>
  </table>
</p>



	    	    
	    <div class="page-header">
      <a name="dates"></a>
      <div class="page-header">
	<h1>Important Dates</h1>
      </div>
      <ul>
	<li>October 20, 2023: First Call for Workshop Papers</li>
	<li>November 15, 2023: Second Call for Workshop Papers</li>
	<li>December 11, 2023: Third Call for Workshop Papers</li>
	<li>December 22, 2023: Workshop paper due</li>
	<li>January 22, 2024: Direct Submission deadline (pre-reviewed ARR & main conference)</li>
	<li>January 25, 2024: Notification of Acceptance</li>
	<li>February 2, 2024: Camera-ready papers due</li>
	<li>February 7, 2024: Submission deadline for Findings papers</li>
	<li>February 7, 2024: Proceedings due</li>
	<li>March 21, 2024: Workshop Date</li>
      </ul>

	    
	    <div class="page-header">
      <a name="submission"></a>
      <div class="page-header">
	<h1>Submission</h1>
      </div>
We invite two types of submissions:
<ul>
	<li>Archival: long (up to 8 pages) or short (up to 4 pages) papers, with unlimited additional pages for references. These papers should report on complete, original and unpublished research and cannot be under submission elsewhere. If accepted, archival papers will appear in the workshop proceedings.
<li>Non-archival: Extended abstracts (up to 2 pages) or copy of submission/publication, which can take two forms: 
<ul>
	<li>Works in progress, that are not yet mature enough for a full submission. Up to 2 pages, with unlimited pages for references.
<li>Already published work, or work currently under submission elsewhere, which can be submitted as a copy of the submission/publication (please indicate the venue where it has been submitted to).
	    </ul>
	</ul>
There are two possible deadlines for the submissions!:
<ul>
	<li>Standard Submission: This deadline, on the 18th of December 2023, is for papers which do not have any reviews through ARR yet. Papers submitted on this deadline will be reviewed by the workshop PCs.
		<ul><li>All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").
		<li><p>Please submit your papers at <a href="https://openreview.net/group?id=eacl.org/EACL/2024/Workshop/UnImplicit">https://openreview.net/group?id=eacl.org/EACL/2024/Workshop/UnImplicit</a></p>
		<li><p>Please use the EACL style templates.</p></ul>
<li>Direct Submission (with reviews): This submission deadline, on January 22nd 2024, is for papers that are either pre-reviewed by ARR and/or rejected from EACL (with reviews).
	<ul>
		<li>For Findings papers looking for a presentation slot: The submission deadline is February 7th 2024.
	<li>All deadlines are 11:59PM UTC-12:00 ("anywhere on Earth").
<li>Please submit using the following link: <a href="https://openreview.net/group?id=eacl.org/EACL/2024/Workshop/UnImplicit_ARR_Commitment">https://openreview.net/group?id=eacl.org/EACL/2024/Workshop/UnImplicit_ARR_Commitment</a></p>
	<li>Please use the EACL style templates.
	    </ul>
	</ul>

	    <p>If you have any questions please email us at unimplicitworkshop -AT- gmail.com</p>

		  <p> We welcome submissions related to, but not limited to, the following topics:
<li>Creating corpora or new annotations for underspecified, vague, or ambiguous language
<li>Studies of annotator disagreement
<li>Methods of resolving underspecification, vagueness, or ambiguity
<li>Studies of how multimodal settings interact with underspecification in language
<li>Ambiguities in non-linguistic domains, like images or videos
<li>Perspectives on the role of vagueness and ambiguity in NLP</ul>


	    <div class="page-header">
      <a name="organizers"></a>
      <div class="page-header">
	<h1>Organizers</h1>
      </div>
        	<h2>Organizers</h2>
      <ul class="list-unstyled">
	<li><a target="_blank" href="https://sandropezzelle.github.io">Sandro Pezzelle</a>, University of Amsterdam</li>
	<li><a target="_blank" href="https://valentinapy.github.io">Valentina Pyatkin</a>, AI2 and University of Washington</li>
	<li><a target="_blank" href="https://esteng.github.io">Elias Stengel-Eskin</a>, UNC Chapel Hil</li>
	<li><a target="_blank" href="https://alisawuffles.github.io">Alisa Liu</a>, University of Washington</li>
	<li><a target="_blank" href="https://dpfried.github.io">Daniel Fried</a>, CMU</li>
      </ul>
        <h2>Advisory Committee</h2>
      <ul class="list-unstyled">
	<li><a target="_blank" href="https://www.ims.uni-stuttgart.de/en/institute/team/Roth-00006/">Michael Roth</a>, Stuttgart University</li>
	<li><a target="_blank" href="https://research.biu.ac.il/researcher/prof-reut-tsarfaty/">Reut Tsarfaty</a>, Bar-Ilan University</li>
	<li><a target="_blank" href="https://www.cs.bgu.ac.il/~yoavg/uni/">Yoav Goldberg</a>, Bar-Ilan University and AI2</li>
      </ul>

      <h3>Program Committee<a name="committee" ></a></h3>

      <ul class="list-unstyled">
<li>Sebastian Pado</li>
<li>Vera Demberg</li>
<li>Elior Sulem</li>
<li>Daniel Hershcovich</li>
<li>Sara Tonelli</li>
<li>Nathan Schneider</li>
<li>Yanai Elazar</li>
<li>Chris Potts</li>
<li>Jennifer Hu</li>
<li>Tiago Timponi Torrent</li>
<li>Michael Elhadad</li>
<li>Zhaofeng Wu</li>
<li>Lucy Li</li>
<li>Sofia Serrano</li>
<li>Dmitry Nikolaev</li>
<li>Nan-Jiang Jiang</li>
<li>Julian Michael</li>
<li>Roma Patel</li>
<li>Ece Takmaz</li>
<li>Aida Nematzadeh</li>
      </ul>

      <br/>
      <br/>
      <br/>
      
    </div>    
  </body>
</html>
